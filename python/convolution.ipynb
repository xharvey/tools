{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fcfitC8RyF1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.applications as app\n",
    "from keras.models import Model  \n",
    "import cv2 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from keras import backend as K  \n",
    "# 返回模型以及数据预处理方法\n",
    "def get_model(name='vgg16'):\n",
    "    if name == 'vgg16':\n",
    "        model = app.vgg16.VGG16(weights=r'C:\\Users\\tomding\\vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "        preprocess_func = app.vgg16.preprocess_input\n",
    "    if name == 'vgg19':\n",
    "        model = app.vgg19.VGG19(weights='imagenet')\n",
    "        preprocess_func = app.vgg19.preprocess_input\n",
    "    if name == 'resnet50':\n",
    "        model = app.resnet50.ResNet50(weights='imagenet')\n",
    "        preprocess_func = app.resnet50.preprocess_input\n",
    "    if name == 'inception_v3':\n",
    "        model = app.inception_v3.InceptionV3(weights='imagenet')\n",
    "        preprocess_func = app.inception_v3.preprocess_input\n",
    "    if name == 'xception':\n",
    "        model = app.xception.Xception(weights='imagenet')\n",
    "        preprocess_func = app.xception.preprocess_input\n",
    "    if name == 'mobilenet':\n",
    "        model = app.mobilenet.MobileNet(weights='imagenet')\n",
    "        preprocess_func = app.mobilenet.preprocess_input\n",
    "    if name == 'densenet':\n",
    "        model = app.densenet.DenseNet121(weights='imagenet')\n",
    "        preprocess_func = app.densenet.preprocess_input\n",
    "\n",
    "    return model, preprocess_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_inniJ55g5Q4"
   },
   "outputs": [],
   "source": [
    "# 读取并根据传入的方法处理图片，然后返回原图处理后的图片\n",
    "def read_img(img_path, preprocess_func, size):\n",
    "    img = cv2.imread(img_path)\n",
    "    processed_img = cv2.resize(img, size)\n",
    "\n",
    "    processed_img = np.expand_dims(processed_img, axis=0)\n",
    "    processed_img = preprocess_func(processed_img)\n",
    "\n",
    "    return img, processed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WpyPXWgQySHA"
   },
   "outputs": [],
   "source": [
    "# 把原始输出图像重构为我们可以看懂得三通道图像\n",
    "def deprocess_image(origin_img):\n",
    "    # 标准化张量: center 为 0., 保证 std 为 0.25\n",
    "    origin_img = (origin_img-origin_img.mean()) / (origin_img.std()+K.epsilon()) * 0.25\n",
    "\n",
    "    # clip to [0, 1] 后面两个参数分别表示最小和最大值\n",
    "    origin_img = np.clip(origin_img+0.5, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    origin_img *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "          origin_img = origin_img.transpose((1, 2, 0))\n",
    "    img = np.clip(origin_img, 0, 255).astype('uint8')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v7zUMZVSyart"
   },
   "outputs": [],
   "source": [
    "# 对一个张量用其L2模进行归一化，避免特别小或特别大的梯度，保证梯度上升过程中梯度平滑\n",
    "def normalize(x):     \n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPaV5mMZyHIa"
   },
   "outputs": [],
   "source": [
    "# 可视化卷积输出或过滤器，输入原始图像，行列数，类型，保存图片名称\n",
    "def vis_conv_filter(images, col_row_num, layer_name, kind):\n",
    "    # 显示多少个图像\n",
    "    row_num = col_row_num\n",
    "    col_num = col_row_num\n",
    "    # 图像大小\n",
    "    size = images[0].shape[1]\n",
    "\n",
    "    fig, axes = plt. subplots(nrows=row_num, ncols=col_num, figsize=(16, 8))\n",
    "    for i in range(row_num):\n",
    "        for j in range(col_num):\n",
    "            if kind == 'filter':\n",
    "                img = images[i+j*col_num]\n",
    "            if kind == 'conv':\n",
    "                img = images[:, :, i+j*col_num]\n",
    "            img = cv2.resize(img, (size, size))\n",
    "            axes[i, j].imshow(img)\n",
    "            # 不显示刻度\n",
    "            axes[i, j].set_xticks([])\n",
    "            axes[i, j].set_yticks([])\n",
    "\n",
    "    plt.savefig(r'visualize_images\\{}\\{}.jpg'.format(kind, layer_name), dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZlQr0ADx-9h"
   },
   "outputs": [],
   "source": [
    "# 可视化热力图，输入原始图像及热图\n",
    "def vis_heatmap(img, heatmap):\n",
    "    #img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure()\n",
    "    # 原图\n",
    "    plt.subplot(221)\n",
    "    plt.imshow(cv2.resize(img, (224, 224)))\n",
    "    plt.axis('off')\n",
    "    # 热力图\n",
    "    plt.subplot(222)\n",
    "    plt.imshow(heatmap)\n",
    "    plt.axis('off')\n",
    "    # 叠加\n",
    "    plt.subplot(212)\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    # 将热力图转换为RGB格式\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # 将热力图应用于原始图像\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    # 这里的0.4是热力图强度因子\n",
    "    superimposed_img = heatmap*0.4 + img\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.axis('off')\n",
    "    # 现实的是错误的但是cv保存正确\n",
    "    cv2.imwrite('heatmap.jpg', superimposed_img)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'visualize_images\\heatmap.jpg', dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OBXlnBzKnatN"
   },
   "outputs": [],
   "source": [
    "# 获取某卷积层的输出 (28, 28, 512)\n",
    "def conv_output(model, layer_name, img):\n",
    "\n",
    "    # 输入图象placeholder\n",
    "    input_img = model.input\n",
    "    # 根据传入的名称在字典里找\n",
    "    try:\n",
    "        out_conv = model.get_layer(layer_name).output\n",
    "    except:\n",
    "        raise Exception('Not layer named {}!'.format(layer_name))\n",
    "\n",
    "    # 截断模型\n",
    "    intermediate_layer_model = Model(inputs=input_img, outputs=out_conv)\n",
    "    # 得到中间结果\n",
    "    intermediate_output = intermediate_layer_model.predict(img)\n",
    "\n",
    "    return intermediate_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECLGLYI5Iurx"
   },
   "outputs": [],
   "source": [
    "# 获取模型某层卷积过滤核感兴趣的图像返回每个卷积核loss最大的图像\n",
    "# 随机初始化一张输入图像，然后求得某个卷积核输出对图像的梯度，更改图像，使得某个卷积核输出值最大化。\n",
    "# 这里需要使损失函数值“最大化”，也就是使某个卷积核激活输出的值最大，所以称为梯度上升。\n",
    "def conv_filter(model, filter_num, layer_name, img):\n",
    "\n",
    "    # 输入图象placeholder\n",
    "    input_img = model.input\n",
    "\n",
    "    # 每层名字和层的字典不包含输入层\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "    # 根据传入的名称在字典里找层\n",
    "    try:\n",
    "        layer_output = layer_dict[layer_name].output\n",
    "        # assert isinstance(output_layer, layers.Conv2D)\n",
    "    except:\n",
    "        raise Exception('Not layer named {}!'.format(layer_name))\n",
    "\n",
    "    #　用于存储使每个卷积核输出最大的输入图像及损失函数值\n",
    "    filtermax_i_v = []\n",
    "  \n",
    "    # 共有512个卷积核layer_output.shape  (?, 28, 28, 512) \n",
    "    for i in range(filter_num):\n",
    "        print('computing {}th filter, still have {}'.format(i+1, filter_num-i-1))\n",
    "        # 建立目标损关函数，我们的优化目标就是最大化指定某层索引为i的卷积核的激活值\n",
    "        # 因为是最大化目标损失函数，而不是最小化，所以成为“梯度上升”\n",
    "        if K.image_data_format() == 'channels_first':             \n",
    "            loss = K.mean(layer_output[:, i, :, :])         \n",
    "        else:             \n",
    "            loss = K.mean(layer_output[:, :, :, i])\n",
    "        # 计算目标损关函数对图像的梯度\n",
    "        grads = K.gradients(loss, input_img)[0]\n",
    "        # 使用上面定义的normalize函数处理梯度\n",
    "        grads = normalize(grads)\n",
    "        # 返回给定输入图像的损失和梯度\n",
    "        # loss.shape, grads.shape () (?, 224, 224, 3)\n",
    "        iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "        # 梯度上升的步长\n",
    "        step = 1.\n",
    "    \n",
    "        fimg = img.copy()\n",
    "\n",
    "        # 运行梯度上升20个步\n",
    "        for j in range(20):\n",
    "            loss_value, grads_value = iterate([fimg])\n",
    "            # 梯度乘以步长更改\n",
    "            fimg += grads_value * step\n",
    "\n",
    "        # 由此产生的输入图像进行解码\n",
    "        fimg = deprocess_image(fimg[0])\n",
    "        # plt.imshow(fimg)  \n",
    "        # plt.show()\n",
    "        filtermax_i_v.append((fimg, loss_value))\n",
    "\n",
    "    # 根据loss从大到小排序过滤器结果\n",
    "    filtermax_i_v.sort(key=lambda x: x[1], reverse=True)\n",
    "    # 返回每个卷积核loss最大的图像\n",
    "    return np.array([f[0] for f in filtermax_i_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KchtxBuqYRoW"
   },
   "outputs": [],
   "source": [
    "# 获取某层卷积图像的热力图\n",
    "def heatmap_output(model, last_conv_layer_name, processed_img):\n",
    "\n",
    "    # 对图像的预测类别\n",
    "    preds = model.predict(processed_img)\n",
    "    # 该类别对应的索引\n",
    "    index = np.argmax(preds[0])\n",
    "    # 预测向量中是该类的元素  model.output.shape (1, 1000) \n",
    "    class_output = model.output[:, index]\n",
    "    # 输出特征图   last_conv_layer.output（1，7，7，512）\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "\n",
    "    # 该类别类对最后一层卷积输出特征图的梯度 返回的是只有一个元素的（1，7，7，512）张量列表\n",
    "    grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
    "\n",
    "    # 平均特定特征图通道上的梯度\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "    pooled_grads_value, conv_layer_output_value = iterate([processed_img])\n",
    "\n",
    "    for i in range(conv_layer_output_value.shape[-1]):\n",
    "        # 将特征图数组的每个通道乘以这个通道对该类别重要程度\n",
    "        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "    # 得到的特征图的逐通道的平均值即为类激活的热力图\n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "    # heatmap与0比较，取其大者\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "7C7M-zomP-f2",
    "outputId": "adb96ab8-353a-4a42-89b7-3a99b4ca9053"
   },
   "outputs": [],
   "source": [
    "img_path = r'cat.jpg'\n",
    "model, preprocess_func = get_model('vgg16')\n",
    "img, processed_img = read_img(img_path, preprocess_func, (224, 224))\n",
    "plt.figure()\n",
    "plt.subplot(131)\n",
    "plt.imshow(img)\n",
    "# opencv的接口使用BGR，而matplotlib.pyplot 则是RGB模式\n",
    "img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(132)\n",
    "plt.imshow(img_RGB)\n",
    "plt.subplot(133)\n",
    "plt.imshow(processed_img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "h95WqdiE9tb3",
    "outputId": "0975f490-bfb0-4a92-afa0-0ba2345fb0a1"
   },
   "outputs": [],
   "source": [
    "layer_name = 'block4_conv3'\n",
    "row_col = 4   # 显示row_col**2个图像\n",
    "# 卷积输出可视化,将处理好的图片送到模型中提取出并画出某层的输出\n",
    "conv_out = conv_output(model, layer_name, processed_img)\n",
    "vis_conv_filter(conv_out, row_col, layer_name, 'conv')\n",
    "# 第一层卷积层类似边缘检测的功能，在这个阶段里，卷积核基本保留图像所有信息 \n",
    "# 随着层数的加深，卷积核输出的内容也越来越抽象，保留的信息也越来越少。\n",
    "# 越深的层数，越多空白的内容，也就说这些内容空白卷积核没有在输入图像中找到它们想要的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CQ_G1BIIJrxh",
    "outputId": "6170bc9d-0dd4-4626-f410-5892b69c80ee"
   },
   "outputs": [],
   "source": [
    "# 卷积核到底是如何识别物体的呢？想要解决这个问题，有一个方法就是去了解卷积核最感兴趣的图像是怎样的。\n",
    "# 我们知道，卷积的过程就是特征提取的过程，每一个卷积核代表着一种特征。如果图像中某块区域与某个卷积核\n",
    "# 的结果越大，那么该区域就越“像”该卷积核。\n",
    "# 基于以上的推论，如果我们找到一张图像，能够使得这张图像对某个卷积核的输出最大，那么我们就说找到了该\n",
    "# 卷积核最感兴趣的图像。\n",
    "# 具体思路：输入一张随机内容的图像II, 求某个卷积核FF对图像的梯度 G=∂F/∂IG=∂F/∂I，用梯度上升的方法迭\n",
    "# 代更新图像 I=I+η∗GI=I+η∗G，ηη是类似于学习率的东西。\n",
    "layer_name = 'block5_conv1'\n",
    "row_col = 6   # 显示row_col**2个图像\n",
    "filter_num = 36\n",
    "# 卷积输出可视化,将处理好的图片送到模型中提取出并画出某层的输出\n",
    "random_img =(np.random.random((1, 224, 224, 3))-0.5)*20 + 128\n",
    "plt.imshow(deprocess_image(random_img[0]))\n",
    "plt.show()\n",
    "filters_out = conv_filter(model, filter_num, layer_name, random_img)\n",
    "vis_conv_filter(filters_out, row_col, layer_name, 'filter')\n",
    "# 低层的卷积核似乎对颜色，边缘信息感兴趣。\n",
    "# 越高层的卷积核，感兴趣的内容越抽象（非常魔幻啊），也越复杂。\n",
    "# 高层的卷积核感兴趣的图像越来越难通过梯度上升获得（block5_conv1有很多还是随机噪声的图像）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "p0mV6z0594Ch",
    "outputId": "fcc96539-13b0-435f-cdd7-d7f49c1d47f2"
   },
   "outputs": [],
   "source": [
    "last_conv_layer_name = 'block5_conv3'\n",
    "# 在图像分类问题中，假设网络将一张图片识别成“猫”的概率是0.9，我想了解到底最后一层的卷积层 \n",
    "# 对这0.9的概率的贡献是多少。换句话时候，假设最后一层卷积层有512个卷积核，我想了解这512个卷积核 \n",
    "# 对该图片是”猫”分别投了几票。投票越多的卷积核，就越确信图片是“猫”，因为它们提取到的特征趋向猫的特征。\n",
    "# 代码中，输入了一图片，然后获得最后一层卷积层的热度图，最后将热度图叠加到原图像，获得图像中起到关键分类作用的部分。\n",
    "heatmap = heatmap_output(model, last_conv_layer_name, processed_img) \n",
    "vis_heatmap(img, heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cQA_0bGSZ2pV"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "卷积可视化.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
